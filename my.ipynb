{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:19.029842Z",
     "start_time": "2025-06-03T21:38:18.771609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df = pd.read_csv('data/Faults.csv')\n",
    "# print(df.shape) #data size\n",
    "# print(df.columns)"
   ],
   "id": "6647e97be98e47e2",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:19.288954Z",
     "start_time": "2025-06-03T21:38:19.269758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/Faults.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['Pastry', 'Z_Scratch', 'K_Scratch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'])\n",
    "y = df['Dirtiness']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split (optional, just for test score)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Train and test one KNN model\n",
    "k = 5\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy (k={k}): {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "# Try multiple cross-validation values\n",
    "cv_list = [3, 5, 10]\n",
    "k_values = range(1, 21)\n",
    "cv_results = {}\n",
    "\n",
    "for cv in cv_list:\n",
    "    scores = []\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        cv_score = cross_val_score(knn, X_scaled, y, cv=cv)\n",
    "        scores.append(cv_score.mean())\n",
    "    cv_results[cv] = scores\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cv, scores in cv_results.items():\n",
    "    plt.plot(k_values, scores, marker='o', label=f'CV={cv}')\n",
    "\n",
    "plt.title(\"KNN Accuracy vs K for Different Cross-Validation Splits\")\n",
    "plt.xlabel(\"Number of Neighbors (k)\")\n",
    "plt.ylabel(\"Cross-Validation Accuracy\")\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"Cross-Validation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "c8470d14e0174629",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:19.426104Z",
     "start_time": "2025-06-03T21:38:19.412770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from scipy.stats import zscore\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "#\n",
    "# # Load dataset\n",
    "# df = pd.read_csv('data/Faults.csv')\n",
    "# print(df.shape)  # data size\n",
    "# print(df.columns)\n",
    "#\n",
    "# # Apply Z-score\n",
    "# z_score = df.apply(zscore)\n",
    "# threshold = 3\n",
    "# df_cleaned = df[(z_score.abs() < threshold).all(axis=1)]\n",
    "#\n",
    "# print(f\"Original Rows: {df.shape[0]}\")\n",
    "# print(f\"Rows After Outlier Removal: {df_cleaned.shape[0]}\")\n",
    "#\n",
    "# # Select one feature for plotting outliers\n",
    "# feature = 'Stains'\n",
    "#\n",
    "# # Find outliers in that column using Z-score\n",
    "# z_feature = zscore(df[feature])\n",
    "# outliers = df[np.abs(z_feature) > threshold]\n",
    "#\n",
    "# # Plot\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(df[feature], np.zeros_like(df[feature]), color='blue', label='Data points', alpha=0.6)\n",
    "# plt.scatter(outliers[feature], np.zeros_like(outliers[feature]), color='red', label='Outliers', alpha=0.8)\n",
    "# plt.title(f'Outlier Detection in \"{feature}\" using Z-Score')\n",
    "# plt.xlabel('Value')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ],
   "id": "3fe1f1362832da29",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:19.551612Z",
     "start_time": "2025-06-03T21:38:19.526134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# df.head()"
   ],
   "id": "e387f12f6d7d15ae",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:19.652Z",
     "start_time": "2025-06-03T21:38:19.634184Z"
    }
   },
   "cell_type": "code",
   "source": "#print(df.sample(10))",
   "id": "7f70085b1ee6f7ee",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:19.775098Z",
     "start_time": "2025-06-03T21:38:19.764307Z"
    }
   },
   "cell_type": "code",
   "source": "#print(df.info)",
   "id": "8d8e53c8966c76e6",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:19.894501Z",
     "start_time": "2025-06-03T21:38:19.887221Z"
    }
   },
   "cell_type": "code",
   "source": "# print(df.isnull().sum()) #are there any missing values ?",
   "id": "c94924aed73cb05",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:20.060275Z",
     "start_time": "2025-06-03T21:38:20.050257Z"
    }
   },
   "cell_type": "code",
   "source": "# print(df.describe) #data insights",
   "id": "13a744a4875f390a",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:20.305058Z",
     "start_time": "2025-06-03T21:38:20.285584Z"
    }
   },
   "cell_type": "code",
   "source": "# print(df.duplicated().sum())",
   "id": "ca39a1f3c379a33",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:20.521404Z",
     "start_time": "2025-06-03T21:38:20.499110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "# # Load dataset\n",
    "# df = pd.read_csv(\"data/Faults.csv\")\n",
    "#\n",
    "# # Remove outliers\n",
    "# def outliars(data):\n",
    "#     for col in data.select_dtypes(include='number').columns:\n",
    "#         q1 = data[col].quantile(0.25)\n",
    "#         q3 = data[col].quantile(0.75)\n",
    "#         iqr = q3 - q1\n",
    "#         lower = q1 - 1.5 * iqr\n",
    "#         upper = q3 + 1.5 * iqr\n",
    "#         data = data[(data[col] >= lower) & (data[col] <= upper)]\n",
    "#     return data\n",
    "#\n",
    "# df_cleaned = outliars(df)\n",
    "#\n",
    "# scaler = StandardScaler()\n",
    "# df_standardized = pd.DataFrame(scaler.fit_transform(df_cleaned), columns=df_cleaned.columns)\n",
    "#\n",
    "# #Save to CSV\n",
    "# #df_standardized.to_csv(\"data/Faults_Standardized.csv\", index=False)\n",
    "# # print(df_standardized.head())\n"
   ],
   "id": "9d2c2cdaddfbcb47",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:20.794004Z",
     "start_time": "2025-06-03T21:38:20.761934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# # Select all features except the last 2 (e.g., fault labels)\n",
    "# df_features = df.iloc[:, :-7]\n",
    "#\n",
    "# # Create scatter plots: feature value vs row index\n",
    "# fig, axs = plt.subplots(len(df_features.columns), 1, figsize=(8, 3 * len(df_features.columns)), dpi=100)\n",
    "#\n",
    "# for i, col in enumerate(df_features.columns):\n",
    "#     axs[i].scatter(df_features.index, df_features[col], alpha=0.6, s=10)\n",
    "#     axs[i].set_ylabel(col)\n",
    "#     axs[i].set_xlabel('Index')\n",
    "#     axs[i].set_title(f'Scatter Plot: {col}')\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ],
   "id": "dbf0347a2352e220",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:21.044114Z",
     "start_time": "2025-06-03T21:38:21.029892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fig, axs = plt.subplots(6, 2, figsize=(14, 18))\n",
    "# colors = ['skyblue', 'tomato']\n",
    "#\n",
    "# for i, col in enumerate(df_cleaned.columns[:6]):\n",
    "#     axs[i][0].hist(df_cleaned[col], bins=30, color=colors[0], edgecolor='black')\n",
    "#     axs[i][0].set_title(f\"Original: {col}\")\n",
    "#\n",
    "#     axs[i][1].hist(df_standardized[col], bins=30, color=colors[1], edgecolor='black')\n",
    "#     axs[i][1].set_title(f\"Standardized: {col}\")\n",
    "#\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ],
   "id": "2bd83973c8eef5b8",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:21.312833Z",
     "start_time": "2025-06-03T21:38:21.300854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df_features = df.iloc[:,:-7]\n",
    "#\n",
    "# fig, axs = plt.subplots(len(df_features.columns), 1, dpi=95, figsize=(7, 3 * len(df_features.columns)))\n",
    "#\n",
    "# i = 0\n",
    "# for col in df_features.columns:\n",
    "#     axs[i].boxplot(df_features[col], vert=False)\n",
    "#     axs[i].set_ylabel(col)\n",
    "#     i+=1\n",
    "# plt.show()"
   ],
   "id": "4e0c46656989b52d",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:21.534575Z",
     "start_time": "2025-06-03T21:38:21.520945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fig, axs = plt.subplots(len(df_cleaned.columns), 1, dpi=95, figsize=(7, 3 * len(df_cleaned.columns)))\n",
    "#\n",
    "# i = 0\n",
    "# for col in df_cleaned.columns:\n",
    "#     axs[i].boxplot(df_cleaned[col], vert=False)\n",
    "#     axs[i].set_ylabel(col)\n",
    "#     i+=1\n",
    "# plt.show()"
   ],
   "id": "108762a22bb5c1e",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:21.724290Z",
     "start_time": "2025-06-03T21:38:21.712332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #correlation\n",
    "# corr = df.corr()\n",
    "#\n",
    "# plt.figure(figsize=(12, 10), dpi=120)\n",
    "# sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm', annot_kws={\"size\": 6})\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.yticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ],
   "id": "967baf4aca49fdd8",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:21.945654Z",
     "start_time": "2025-06-03T21:38:21.939662Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "926a6455c843c6ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:22.142822Z",
     "start_time": "2025-06-03T21:38:22.123684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# import numpy as np\n",
    "#\n",
    "# def forward_selection(X, y, model, max_features=None):\n",
    "#     x_selected = []\n",
    "#     c_rate_best = -np.inf\n",
    "#\n",
    "#     if max_features is None:\n",
    "#         max_features = X.shape[1]\n",
    "#\n",
    "#     while len(x_selected) < max_features:\n",
    "#         x_selected_last_iter = list(x_selected)\n",
    "#         c_rate = []\n",
    "#\n",
    "#         for j in range(X.shape[1]):\n",
    "#             if j not in x_selected:\n",
    "#                 x_temp = x_selected + [j]\n",
    "#                 scores = cross_val_score(model, X[:, x_temp], y, cv=5)\n",
    "#                 c_rate.append(np.mean(scores))\n",
    "#             else:\n",
    "#                 c_rate.append(-np.inf)\n",
    "#\n",
    "#         x_best_addition = np.argmax(c_rate)\n",
    "#\n",
    "#         if c_rate[x_best_addition] > c_rate_best:\n",
    "#             x_selected.append(x_best_addition)\n",
    "#             c_rate_best = c_rate[x_best_addition]\n",
    "#         else:\n",
    "#             break\n",
    "#\n",
    "#     return x_selected\n"
   ],
   "id": "2df3e7260cf44c7b",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T21:38:22.299096Z",
     "start_time": "2025-06-03T21:38:22.286353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# # Load dataset\n",
    "# df = pd.read_csv('data/Faults.csv')\n",
    "#\n",
    "# # Define features and label\n",
    "# X = df.drop(columns=['Pastry', 'Z_Scratch', 'K_Scratch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'])\n",
    "# y = df['Pastry']\n",
    "#\n",
    "# # Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "#\n",
    "# # Split for model accuracy check\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "#\n",
    "# # Create and train Naive Bayes model\n",
    "# model = GaussianNB()\n",
    "# model.fit(X_train, y_train)\n",
    "#\n",
    "# # Predict\n",
    "# y_pred = model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Naive Bayes Accuracy:\", round(accuracy * 100, 1), \"%\")\n",
    "#\n",
    "# # Forward Selection function\n",
    "# def forward_selection(X, y, model, max_features=None):\n",
    "#     x_selected = []\n",
    "#     c_rate_best = -np.inf\n",
    "#     if max_features is None:\n",
    "#         max_features = X.shape[1]\n",
    "#\n",
    "#     while len(x_selected) < max_features:\n",
    "#         c_rate = []\n",
    "#         for j in range(X.shape[1]):\n",
    "#             if j not in x_selected:\n",
    "#                 x_temp = x_selected + [j]\n",
    "#                 scores = cross_val_score(model, X[:, x_temp], y, cv=5)\n",
    "#                 c_rate.append(np.mean(scores))\n",
    "#             else:\n",
    "#                 c_rate.append(-np.inf)\n",
    "#         x_best_addition = np.argmax(c_rate)\n",
    "#         if c_rate[x_best_addition] > c_rate_best:\n",
    "#             x_selected.append(x_best_addition)\n",
    "#             c_rate_best = c_rate[x_best_addition]\n",
    "#         else:\n",
    "#             break\n",
    "#     return x_selected\n",
    "#\n",
    "# # Apply forward selection\n",
    "# selected_features = forward_selection(X_scaled, y, model, max_features=3)\n",
    "# print(\"Selected feature indices:\", selected_features)\n"
   ],
   "id": "2f269956990b1447",
   "outputs": [],
   "execution_count": 79
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
